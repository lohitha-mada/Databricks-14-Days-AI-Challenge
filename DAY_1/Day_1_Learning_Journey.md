# Day 1 â€“ Getting Started with Databricks ğŸš€

Today, I officially started my **Databricks learning journey** as part of the *Databricks 14 Days AI Challenge*.  
Most of the day was spent understanding **why Databricks exists**, **what problems it solves**, and **how it is used in real-world data platforms**.

This day was all about building a **strong foundation** before diving deeper into Spark and AI workflows.

---

## ğŸ’¡ What I Learned Today

### ğŸ”¹ What is Databricks?
Databricks is a **unified data analytics platform** built on top of **Apache Spark**, designed to handle **large-scale data engineering, analytics, and machine learning workloads** on the cloud.

It brings data teams together by providing:
- Scalable distributed computing
- Collaborative notebooks
- Optimized Spark performance
- Support for SQL, Python, Scala, and R in one place

---

### ğŸ”¹ Why Databricks over Pandas and Hadoop?

While tools like **Pandas** are great for small datasets and local analysis, they are not designed to handle massive data volumes.

Similarly, **Hadoop** introduced distributed data processing but often comes with:
- Complex setup
- Slower disk-based processing
- Multiple tools stitched together

**Databricks stands out because:**
- It processes data **in-memory** using Spark (much faster)
- It scales effortlessly for **big data**
- It simplifies infrastructure and maintenance
- It supports **end-to-end analytics** on a single platform

ğŸ‘‰ This makes Databricks the preferred choice for modern, large-scale data workloads.

---

### ğŸ”¹ Understanding Lakehouse Architecture
One of the most interesting concepts today was the **Lakehouse architecture**.

It combines:
- The **flexibility and low cost** of data lakes
- The **performance and reliability** of data warehouses

This approach enables:
- ACID transactions
- Schema enforcement
- BI + ML on the same data
- A single source of truth for analytics

---

### ğŸ”¹ Exploring the Databricks Workspace
I explored how Databricks organizes work through:
- **Workspace** â†’ notebooks, folders, and projects
- **Compute** â†’ clusters to run workloads
- **Data Explorer** â†’ databases, tables, and files

Understanding the workspace layout made it much easier to visualize how teams collaborate in real production environments.

---

### ğŸ”¹ Databricks in the Real World ğŸŒ
Learning that industry leaders like:
- **Netflix** (recommendation systems & large-scale analytics)
- **Shell** (energy data analytics)
- **Comcast** (customer and streaming analytics)

use Databricks gave me strong confidence that this platform is **industry-proven and future-ready**.

---

## ğŸ›  Hands-On Work Completed

âœ” Created a **Databricks Community Edition account**  
âœ” Explored the platform UI in detail  
âœ” Navigated through Workspace, Compute, and Data Explorer  
âœ” Created my **first Databricks notebook**  
âœ” Ran basic **PySpark DataFrame operations**  
âœ” Imported **CSV and JSON files**  
âœ” Executed **SQL queries** on structured data  

---

## ğŸ“¸ Snapshots & Resources
This folder also contains:
PySpark_practice.png
SQL_Products.png
SQL_customer.png
- Sample CSV and JSON files used for SQL practice

These snapshots reflect my **hands-on exploration and learning process**.

---

## ğŸ¯ Key Takeaway
Day 1 was not about writing complex code â€”  
it was about understanding **the bigger picture of modern data platforms** and building clarity before moving forward.

Excited to continue this journey and share my learning **day by day** ğŸš€

---

âœ… **Day 1 Completed**

